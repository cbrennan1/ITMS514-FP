---
title: "Forest Fires"
author: "Sarvesh Kaushik, Jay Gupta, Colin Brennan"
date: "4/27/2022"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}

library(ggplot2)
library(ISLR)
library(tidyverse)
library(dplyr)
library(tigerstats)
library(MLmetrics)
library(MASS)
library(e1071)
library(caret)
```

**Input Region CSV**
```{r}
forestfireregion1 <- read.csv("/Users/jaygupta/Downloads/ForestFireRegion1.csv", sep = ",") 
```

**Data Preparation Region**
```{r}
names(forestfireregion1)[names(forestfireregion1)=="√Ø..day"] <- "day"
dim(forestfireregion1)
str(forestfireregion1)
summary(forestfireregion1)
head(forestfireregion1)
sum(is.na(forestfireregion1))
sum(duplicated(forestfireregion1))
```

<h5> Region 1 is a data frame that contains 122 observations and 14 features.  There are no duplicate or missing values. </h5>



**Bar Plots Region**

```{r}
# Region 1 Classes
ggplot(data = forestfireregion1) + geom_bar(mapping = aes(x = Classes))

# Frequency of rain and temperature to understand them better

as.data.frame(table(forestfireregion1$Temperature))
as.data.frame(table(forestfireregion1$Rain))

# Temperature has most values concentrated in categories 31, 32, 33 and 35. Only a few observations made for categories 22, 24 and 37.
# Rain has most values concentrated in categories 0, 0.1 and 0.3. There are quite a lot of observations with less frequencies. 

#Classes compared with Wind Speed

ggplot(data = forestfireregion1, aes(x = Ws)) +
  geom_bar(aes(fill = Classes)) 

#Classes per Month
ggplot(data = forestfireregion1, aes(x = month)) +
  geom_bar(aes(fill = Classes)) 

#Temperature VS Classes
ggplot(data = forestfireregion1, aes(x = Temperature)) +geom_histogram(aes(fill = Classes),bins = 30)

#Rain vs Fire
ggplot(data = forestfireregion1, aes(x = Rain)) + geom_histogram(aes(fill = Classes), bins =10, color = "black")
```

<h5>The Chances of fire are greater when less Rain Precepiration</h5>

**EDA For Temperature**
```{r}
temperature=forestfireregion1$Temperature
h1=hist(temperature,ylim=c(0,40))
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
hist(temperature,main="Maximum daily temperature",xlab="Temperature in degrees Fahrenheit",xlim=c(0,40),col="darkmagenta",freq=FALSE)
boxplot(day~Temperature,data=forestfireregion1,main="Measure of temperature per day",xlab="Temperature",ylab="Days")
boxplot(Rain~Temperature,data=forestfireregion1,main="Measure of rain according to the temperature",xlab="Temperature",ylab="Rain")
ggplot(data = forestfireregion1, aes(x = Temperature)) +geom_histogram(aes(fill = Classes),bins = 30)
```

**EDA For Wind Speed**
```{r}
ws=forestfireregion1$Ws
h1=hist(ws,ylim=c(0,40))
text(h1$mids,h1$counts,labels=h1$counts, adj=c(0.5, -0.5))
hist(ws,main="Maximum daily Wind Speed",xlab="Wind Speed",xlim=c(0,30),col="darkmagenta",freq=FALSE)
boxplot(day~Ws,data=forestfireregion1,main="Measure of wind speed per day",xlab="Wind Speed",ylab="Days")
boxplot(Rain~Ws,data=forestfireregion1,main="Measure of rain according to the wind speed",xlab="Wind Speed",ylab="Rain")
ggplot(data = forestfireregion1, aes(x = Ws)) +geom_histogram(aes(fill = Classes),bins = 30)
```

# Data Analysis


## QQplot
```{r}
qqnorm(forestfireregion1$Temperature, pch=2) 
qqline(forestfireregion1$Temperature, col ="green")

qqnorm(forestfireregion1$Rain, pch=2)
qqline(forestfireregion1$Rain, col ="red")

qqnorm(forestfireregion1$RH, pch=2)
qqline(forestfireregion1$RH, col ="blue")

qqnorm(forestfireregion1$Ws, pch=2)
qqline(forestfireregion1$Ws, col ="yellow")
```


<h5> qqplot gives us the idea about the distribution of data. In the above graphs it can be seen that Tempreture, Rain, RH and Ws are having data, aproximatly noramlly distributed as most of the points lies on the qqline. </h5>

# Hypothesis Testing:
Consider the hypothesis as given below,

 H0: ùúé(junemonth$Rain) = ùúé(julymonth$Rain)
 H1: ùúé(junemonth$Rain) ‚â† ùúé(julymonth$Rain)

```{r}
junemonth=subset.data.frame(forestfireregion1,forestfireregion1$month==6)
summary(junemonth)
julymonth=subset.data.frame(forestfireregion1,forestfireregion1$month==7)
summary(julymonth)
s1=sd(junemonth$Rain)
s2=sd(julymonth$Rain)
n1=length(junemonth$Rain)
n2=length(julymonth$Rain)
fvalue=s1^2/s2^2
fvalue
alpha=0.05
f1=qf(alpha/2,n1-1,n2-1)
f1
f2=qf(1-alpha/2,n1-1,n2-1)
f2
var.test(julymonth$Rain,junemonth$Rain,alternative = "two.sided",conf.level = 0.95)
```

<h5> The variances are not equal because the p value is much lesser than significance level and the fvalue doesn't lie between f1 and f2, hence we reject the hypothesis. </h5>

## For unknown mean and unequal variances
> Consider the hypothesis as given below,
> H0: ùùª(junemonth$Rain) = ùùª(julymonth$Rain)
> H1: ùùª(junemonth$Rain) ‚â† ùùª(julymonth$Rain)

```{r}
t.test(junemonth$Rain,julymonth$Rain,var.equal = FALSE,conf.level = 0.95)
```
<h5> We are using t.test because we have two means and the variance are unknown and are not equal. The p-value is greater than alpha i.e., 0.05. So we can accept the null hypothesis H0 and agree that the increase of total rain in the month of June is equal to the increase of total rain in the month of July. <h/5>

## Hypothesis testing on one sample:
> Consider the hypothesis as given below,
> H0: ùùª(RH) = 68
> H1: ùùª(RH) ‚â† 68

```{r}
fr<- forestfireregion1 %>% subset(Classes == "fire", select= RH)
nofr <- forestfireregion1 %>% subset(Classes == "not fire", select= RH)
t.test(nofr, mu = 68)
```
<h5>
According to p value we should reject H0, when there is no fire average relative humidity would not be equal to 68.
</h5>

## Corelation

<h5>

r<0.3, weak correlation

0.3<r<0.7, moderate correlation

r>0.7, high correlation

</h5>
  
**Multiple Regression Testing Region 1**

```{r}
i <- sample(2, nrow(forestfireregion1), replace=TRUE, prob=c(0.8, 0.2))
Region1Training = forestfireregion1[i==1,]
Region1Testing = forestfireregion1[i==2,]                    
```

## Correlation of training dataset attributes except Classes.

```{r}  
cor(subset(Region1Training, select=-Classes))
```

**Forward Step Regression Testing Temperature**

```{r}
intercept_only <- lm(Temperature ~ 1, data=Region1Training[,1:14])
all <- lm(Temperature~., data=Region1Training[,1:14])
forward <- stepAIC (intercept_only, direction='forward',scope = formula(all))
forward$anova
ypred_forward = predict(object = forward, newdata = Region1Testing[,1:14])
MAE(y_pred = ypred_forward, y_true = Region1Testing$Temperature)
MSE(y_pred = ypred_forward, y_true = Region1Testing$Temperature)
```

**Backwards Step Regression Testing Temperature**

```{r}
backward <- stepAIC (all, direction='backward')
backward$anova
summary(backward)
ypred_backward = predict(object = backward, newdata = Region1Testing[,1:14])
MAE(y_pred = ypred_backward, y_true = Region1Testing$Temperature)
MSE(y_pred = ypred_backward, y_true = Region1Testing$Temperature)
```

## Response as Wind                                                             

**Forward Step Regression Testing Wind Speed**

```{r}
intercept_only <- lm( Ws~ 1, data=Region1Training[,1:14])
all <- lm(Ws~., data=Region1Testing[,1:14])
forward <- stepAIC (intercept_only, direction='forward',scope = formula(all))                                                                
forward$anova
summary(forward)
ypred_for <- predict(object = forward, newdata = Region1Testing[,1:14])
MAE(y_pred = ypred_for, y_true = Region1Testing$Ws)
MSE(y_pred = ypred_for, y_true = Region1Testing$Ws)
```   

**Backwards Step Regression Testing Wind Speed** 

```{r}              
backward <- stepAIC (all, direction='backward')
backward$anova  
summary(backward)
ypred_bac <- predict(object = backward, newdata = Region1Testing[,1:14])
MAE(y_pred = ypred_bac,y_true = Region1Testing$Ws)
MSE(y_pred = ypred_bac,y_true = Region1Testing$Ws)             
``` 

<h5> According to MAE, MSE, R-Square and  Resedual Standard Error Backward stepwise model would be suitable fit over the forward stepwise model.  </h5>
  
## Confidence and Predection Intervals

```{r}
fitLmtest1 <- lm(FFMC~ Ws, data=forestfireregion1)
new <- data.frame(Ws = 22)
predict(fitLmtest1 , new)
predict(fitLmtest1, new, interval="confidence") 
predict(fitLmtest1, new, interval="prediction")
```

       
       
## Confidence and Predection Intervals

```{r}
fitLmtest1 <- lm(FFMC~ Ws, data=forestfireregion1)
new <- data.frame(Ws = 22)


predict(fitLmtest1 , new)
predict(fitLmtest1, new, interval="confidence") 
predict(fitLmtest1, new, interval="prediction")


fitLmtest2 <- lm(Temperature~ Rain, data=forestfireregion1)
new <- data.frame(Rain = 15)

predict(fitLmtest2 , new)
predict(fitLmtest2, new, interval="confidence") 
predict(fitLmtest2, new, interval="prediction")



fitLmtest3 <- lm(RH ~ Rain, data=forestfireregion1)
new <- data.frame(Rain = 15)

predict(fitLmtest3 , new)
predict(fitLmtest3, new, interval="confidence") 
predict(fitLmtest3, new, interval="prediction")

```
       
       
       
       
       
       
       
       
       
## Association between the Numerical Variable and Categorical Variable

```{r}
aov1 <- aov(Rain ~Classes, data=forestfireregion1)
summary(aov1)

aov2 <- aov(FFMC ~Classes, data=forestfireregion1)
summary(aov2)


aov2 <- aov(RH ~Classes, data=forestfireregion1)
summary(aov2)


aov2 <- aov(Temperature ~Classes, data=forestfireregion1)
summary(aov2)





```

## Performing SVM (Support Vector Machine) Regression on forestfireregion1 dataset to predict the attribute "Classes".

## Applying SVM to the data to predict "Classes" and reporting the accuracy using 10-fold cross validation. 

```{r}
intrain= createDataPartition(y=forestfireregion1$Classes,p=0.7,list=F) 
# Creating a data partition for training and testing the dataset.
training=forestfireregion1[intrain,]
testing=forestfireregion1[-intrain,]
any_na(forestfireregion1)
training[["Classes"]]=factor(training[["Classes"]])
trctrl = trainControl(method = "repeatedcv", number = 10, repeats = 3)
svm_Linear = train(Classes ~., data = training, method = "svmLinear",
trControl=trctrl,preProcess = c("center", "scale"),tuneLength = 10)
svm_Linear
test_pred = predict(svm_Linear, newdata = testing)
test_pred
confusionMatrix(table(test_pred, testing$Classes))
```

## Using the grid search functionality when training to optimize the C parameter of the SVM.
 
```{r}
grid <- expand.grid(C = c(0,0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2,5))
svm_Linear_Grid = train(Classes ~., data = training, method = "svmLinear", trControl=trctrl, preProcess = c("center", "scale"), tuneGrid = grid,
tuneLength = 10)
svm_Linear_Grid
plot(svm_Linear_Grid)
## We chose the C value as displayed above and the final C value used for optimal model was C = 5.
test_pred_grid = predict(svm_Linear_Grid, newdata = testing)
test_pred_grid
confusionMatrix(table(test_pred_grid, testing$Classes))
## The final model accuracy is 94.29% for the test set.
```
